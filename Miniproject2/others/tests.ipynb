{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUqxb2sCRlzP"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'C:\\\\Users\\\\franc\\\\Desktop\\\\EPFL\\\\Deep Learning\\\\Miniprojects\\\\Proj_338157_338681_311699\\\\Miniproject2\\\\model.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('model.py'))))\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n-cPmIhvQ2FG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qmg9kJmxRre6"
   },
   "outputs": [],
   "source": [
    "def test_linear():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    linear_torch = nn.Linear(100, 1000)\n",
    "    initial_weight = linear_torch.weight.clone()\n",
    "    initial_bias = linear_torch.bias.clone()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = linear_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    linear_model = model.Linear(100, 1000)\n",
    "    assert linear_model.weight.shape == initial_weight.shape\n",
    "    assert linear_model.bias.shape == initial_bias.shape\n",
    "    assert torch.allclose(linear_model.weight.mean(), initial_weight.mean(), atol=1e-3, rtol=1e-2)\n",
    "    assert torch.allclose(linear_model.weight.std(), initial_weight.std(), atol=1e-3, rtol=1e-2)\n",
    "\n",
    "    linear_model.weight = initial_weight\n",
    "    linear_model.bias = initial_bias\n",
    "    linear_model.zero_grad()\n",
    "    output_model = linear_model(x_test)\n",
    "    gradwrtinput = linear_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    assert torch.allclose(linear_torch.weight.grad, linear_model.weight.grad)\n",
    "    assert torch.allclose(linear_torch.bias.grad, linear_model.bias.grad)\n",
    "    \n",
    "    print('Linear layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652271010973,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "nhbFLX_rU4iR",
    "outputId": "515cfc37-ed93-424c-f76e-4ad7dcc3ca94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer ok\n"
     ]
    }
   ],
   "source": [
    "test_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qS-7JZHohE4-"
   },
   "outputs": [],
   "source": [
    "def test_conv():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    conv_torch = nn.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "    initial_weight = conv_torch.weight.clone()\n",
    "    initial_bias = conv_torch.bias.clone()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 32, 50, 50)).normal_().requires_grad_()\n",
    "    output = conv_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    conv_model = model.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "    assert conv_model.weight.shape == initial_weight.shape\n",
    "    assert conv_model.bias.shape == initial_bias.shape\n",
    "    assert torch.allclose(conv_model.weight.mean(), initial_weight.mean(), atol=1e-2, rtol=1e-2)\n",
    "    assert torch.allclose(conv_model.weight.var(), initial_weight.var(), atol=1e-2, rtol=1e-2)\n",
    "\n",
    "    conv_model.weight = initial_weight\n",
    "    conv_model.bias = initial_bias\n",
    "    conv_model.zero_grad()\n",
    "    output_model = conv_model(x_test)\n",
    "    gradwrtinput = conv_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output, atol=1e-2)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2)\n",
    "    assert torch.allclose(conv_torch.weight.grad, conv_model.weight.grad, atol=1e-2)\n",
    "    assert torch.allclose(conv_torch.bias.grad, conv_model.bias.grad, atol=1e-2)\n",
    "    \n",
    "    print('Convolutional layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1652271567100,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "-Jj-tCSXjg2f",
    "outputId": "a37b2a3c-fca5-41bf-fec5-6c6b289cdc47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional layer ok\n"
     ]
    }
   ],
   "source": [
    "test_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_relu():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    relu_torch = nn.ReLU()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = relu_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    relu_model = model.ReLU()\n",
    "    output_model = relu_model(x_test)\n",
    "    gradwrtinput = relu_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    \n",
    "    print('ReLU layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU layer ok\n"
     ]
    }
   ],
   "source": [
    "test_relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sigmoid():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    sigmoid_torch = nn.Sigmoid()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = sigmoid_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    sigmoid_model = model.Sigmoid()\n",
    "    output_model = sigmoid_model(x_test)\n",
    "    gradwrtinput = sigmoid_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    \n",
    "    print('Sigmoid layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid layer ok\n"
     ]
    }
   ],
   "source": [
    "test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mse():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    mse_torch = nn.MSELoss()\n",
    "    # Batch size x input dimension\n",
    "    target = torch.zeros((5, 100)).normal_()\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = mse_torch(x_test, target)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    mse_model = model.MSE()\n",
    "    output_model = mse_model(x_test, target)\n",
    "    gradwrtinput = mse_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2, rtol=1e-2)\n",
    "    \n",
    "    print('MSE layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE layer ok\n"
     ]
    }
   ],
   "source": [
    "test_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nearest_upsampling():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    upsample_torch = nn.Upsample(scale_factor=3)\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 32, 8, 8)).normal_().requires_grad_()\n",
    "    output = upsample_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    upsample_model = model.NearestUpsampling(scale_factor=3)\n",
    "    output_model = upsample_model(x_test)\n",
    "    gradwrtinput = upsample_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2, rtol=1e-2)\n",
    "    \n",
    "    print('Nearest upsample layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest upsample layer ok\n"
     ]
    }
   ],
   "source": [
    "test_nearest_upsampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6fXNctqSDhZi"
   },
   "outputs": [],
   "source": [
    "def test_all():\n",
    "    test_linear()\n",
    "    test_conv()\n",
    "    test_relu()\n",
    "    test_sigmoid()\n",
    "    test_mse()\n",
    "    test_nearest_upsampling()\n",
    "    print('All tests ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1652271531295,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "LPF4A8pJDrd2",
    "outputId": "d2d1537d-fd82-4e2e-e056-d1d54d2dec31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer ok\n",
      "Convolutional layer ok\n",
      "ReLU layer ok\n",
      "Sigmoid layer ok\n",
      "MSE layer ok\n",
      "Nearest upsample layer ok\n",
      "All tests ok\n"
     ]
    }
   ],
   "source": [
    "test_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMBZ0Xu5ksaAiymbAn7TS2",
   "collapsed_sections": [],
   "name": "tests.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "924c84e30a2a0a804f16c763f19e96b94813a24908351fd66a7500b9fea63b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
