{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d5abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2ed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "reload(model)\n",
    "Sequential = model.Sequential\n",
    "ReLU = model.ReLU\n",
    "Conv2d = model.Conv2d\n",
    "NNUpsampling = model.NNUpsampling\n",
    "Sigmoid = model.Sigmoid\n",
    "MSE = model.MSE\n",
    "Upsampling = model.Upsampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d85e09",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f69f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "TRAIN_PATH = '../data/train_data.pkl'\n",
    "train_noisy_imgs_input, train_noisy_imgs_target = load(TRAIN_PATH)\n",
    "train_noisy_imgs_input = train_noisy_imgs_input/255\n",
    "train_noisy_imgs_target = train_noisy_imgs_target/255\n",
    "training_set_size,num_channels,y_size,x_size = train_noisy_imgs_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0806b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, in_channels=3, out_channels=3, lr=1e-3):\n",
    "        # instantiate model + optimizer + loss function + any other stuff you need\n",
    "        self.model = Sequential(\n",
    "                        Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "                        ReLU(),\n",
    "                        Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "                        ReLU(),\n",
    "                        Upsampling(scale_factor=2, in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "                        ReLU(),\n",
    "                        Upsampling(scale_factor=2, in_channels=16, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                        Sigmoid()\n",
    "                        )\n",
    "        self.criterion = MSE()\n",
    "        self.lr = lr\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        ## This loads the parameters saved in bestmodel.pth into the model\n",
    "        pass\n",
    "\n",
    "    def train(self, train_input, train_target):\n",
    "        # train ̇input: tensor of size (N, C, H, W) containing a noisy version of the images.\n",
    "        # train target: tensor of size (N, C, H, W) containing another noisy version of the\n",
    "        # same images, which only differs from the input by their noise.\n",
    "        batch_size = 32\n",
    "        nb_epochs = 3\n",
    "        self.losses = []\n",
    "        avg_loss = 0\n",
    "\n",
    "        for e in range(nb_epochs):\n",
    "            print('Doing epoch %d'%e)\n",
    "            for b in range(0, train_input.size(0), batch_size):\n",
    "                if b % 5 == 0:\n",
    "                    self.losses.append(avg_loss/5)\n",
    "                    avg_loss = 0\n",
    "                if b%50 ==0:\n",
    "                    print(self.losses[-1])\n",
    "                # forward pass\n",
    "                output = self.model(train_input[b:b+batch_size])\n",
    "                loss = self.criterion(output, train_target[b:b+batch_size])\n",
    "                avg_loss+=loss.item()\n",
    "                # make step\n",
    "                self.model.zero_grad()\n",
    "                gradient = self.criterion.backward()\n",
    "                gradient = self.model.backward(gradient)\n",
    "                for (parameter,_) in self.model.param():\n",
    "                    parameter -= parameter.grad*self.lr\n",
    "\n",
    "    def predict(self, test_input):\n",
    "        #:test ̇input: tensor of size (N1, C, H, W) that has to be denoised by the trained\n",
    "        # or the loaded network.\n",
    "        #: returns a tensor of the size (N1, C, H, W)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c11146",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing epoch 0\n",
      "0.0\n",
      "0.06268877759575844\n",
      "0.05846758931875229\n",
      "0.0418437659740448\n",
      "0.03524077385663986\n",
      "0.0354213535785675\n",
      "0.03451731503009796\n",
      "0.025138859078288077\n",
      "0.02949148416519165\n",
      "0.037558384239673615\n",
      "0.022657349333167077\n",
      "0.027885977178812027\n",
      "0.027602728083729745\n",
      "0.025547520816326143\n",
      "0.02397290915250778\n",
      "0.02739260345697403\n",
      "0.0215676698833704\n",
      "0.023305001854896545\n",
      "0.025292449817061424\n",
      "0.02468079961836338\n",
      "0.023063242062926294\n",
      "0.02343892939388752\n",
      "0.021910065785050392\n",
      "0.022892505675554276\n",
      "0.022123095765709876\n",
      "0.022032814845442773\n",
      "0.02177177295088768\n",
      "0.023371782898902894\n",
      "0.022373880073428155\n",
      "0.021278548613190652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cx/500d947x7sz2w1kz1n78cgwr0000gn/T/ipykernel_87028/2472951264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mourModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mourModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_noisy_imgs_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_noisy_imgs_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cx/500d947x7sz2w1kz1n78cgwr0000gn/T/ipykernel_87028/550881568.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_input, train_target)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mparameter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/DL/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradwrtoutput)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/DL/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradwrtoutput)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/DL/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *gradwrtoutput)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Get the unfolded versions of the input, gradient w.r.t. output and kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0minput_unfolded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mgradwrtoutput_unfolded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradwrtoutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/ada/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36munfold\u001b[0;34m(input, kernel_size, dilation, padding, stride)\u001b[0m\n\u001b[1;32m   4679\u001b[0m         \u001b[0massert_int_or_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stride\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim2col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4682\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4683\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Error: Only 4D input Tensors are supported (got {}D)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ourModel = Model()\n",
    "ourModel.train(train_noisy_imgs_input, train_noisy_imgs_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ourModel.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x,x,x,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfae956",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda deep_list: [item for sublist in deep_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f21363",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77891da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before: ',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcad328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61f371659e15671c4bf19c781ff73734bc385c323133a3685f5b4f679a2745d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
