{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d5abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2ed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d85e09",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f69f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "TRAIN_PATH = '../miniproject_dataset/train_data.pkl'\n",
    "train_noisy_imgs_input, train_noisy_imgs_target = load(TRAIN_PATH)\n",
    "train_noisy_imgs_input = train_noisy_imgs_input/255\n",
    "train_noisy_imgs_target = train_noisy_imgs_target/255\n",
    "training_set_size,num_channels,y_size,x_size = train_noisy_imgs_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0806b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        # instantiate model + optimizer + loss function + any other stuff you need\n",
    "        self.model = Sequential(Conv2d(in_channels, 16, 3, stride=2),\n",
    "                                  ReLU(),\n",
    "                                  Conv2d(16, 32, 2, stride=2),\n",
    "                                  ReLU(),\n",
    "                                  NNupsampling(scale_factor=2),\n",
    "                                  Conv2d(32, 32, 2, stride=1),\n",
    "                                  ReLU(),\n",
    "                                  NNupsampling(scale_factor=2),\n",
    "                                  Conv2d(32, 32, 2, stride=1),\n",
    "                                  Sigmoid()\n",
    "                                 )\n",
    "        self.criterion = MSE()\n",
    "    \n",
    "    def load_pretrained_model(self):\n",
    "        ## This loads the parameters saved in bestmodel.pth into the model\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_input, train_target):\n",
    "        # train ̇input: tensor of size (N, C, H, W) containing a noisy version of the images.\n",
    "        # train target: tensor of size (N, C, H, W) containing another noisy version of the\n",
    "        # same images, which only differs from the input by their noise.\n",
    "        batch_size = 4\n",
    "        nb_epochs = 10\n",
    "        self.losses = [0 for x in range(nb_epochs)]\n",
    "        for e in range(nb_epochs):\n",
    "            print('Doing epoch %d'%e)\n",
    "            for b in range(0, train_input.size(0), batch_size):\n",
    "                # forward pass\n",
    "                output = self.model(train_input[b:b+batch_size])\n",
    "                loss = self.criterion(output, train_target[b:b+batch_size]) \n",
    "                self.losses[e] += loss.item()\n",
    "                # make step\n",
    "                self.model.zero_grad()\n",
    "                gradient = self.criterion.backward()\n",
    "                gradient = self.model.backward(gradient)\n",
    "                \n",
    "                for (parameter,_) in model.param():\n",
    "                    parameter -= parameter.grad\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        #:test ̇input: tensor of size (N1, C, H, W) that has to be denoised by the trained\n",
    "        # or the loaded network.\n",
    "        #: returns a tensor of the size (N1, C, H, W)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c11146",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing epoch 0\n",
      "layer nr 0\n",
      "Before layer:  torch.Size([4, 3, 32, 32])\n",
      "After layer:  torch.Size([1, 16, 15, 15])\n",
      "layer nr 1\n",
      "Before layer:  torch.Size([1, 16, 15, 15])\n",
      "After layer:  torch.Size([16, 15, 15])\n",
      "layer nr 2\n",
      "Before layer:  torch.Size([16, 15, 15])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jd/z25nw7dx5w9bd064vtrxbjvw0000gq/T/ipykernel_5535/2472951264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mourModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mourModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_noisy_imgs_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_noisy_imgs_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jd/z25nw7dx5w9bd064vtrxbjvw0000gq/T/ipykernel_5535/135613430.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_input, train_target)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/MA2/3_DeepLearning/project/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/MA2/3_DeepLearning/project/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer nr \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Before layer: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After layer: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EPFL/MA2/3_DeepLearning/project/Proj_338157_338681_311699/Miniproject2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ourModel = Model()\n",
    "ourModel.train(train_noisy_imgs_input, train_noisy_imgs_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ourModel.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [x,x,x,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfae956",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda deep_list: [item for sublist in deep_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f21363",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77891da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before: ',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcad328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
