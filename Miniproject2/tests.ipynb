{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16924,
     "status": "ok",
     "timestamp": 1652270833110,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "Z0WL1wMgQf5b",
    "outputId": "a8d69c8d-fe07-430c-97ef-85e91e5abaf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrK7HMFsQlnZ"
   },
   "outputs": [],
   "source": [
    "DRIVE_PATH = 'drive/MyDrive/Proj_338157_338681_311699/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vm2uxqHRQmih"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUeGL2MnRG2o"
   },
   "outputs": [],
   "source": [
    "sys.path.append(DRIVE_PATH + 'Miniproject_2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUqxb2sCRlzP"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "l9ZyF8esSlB3"
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652270843174,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "b03Y74pNSoye",
    "outputId": "ce2097fa-7416-497f-9c2c-ace03caa11f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from 'C:\\\\Users\\\\franc\\\\Desktop\\\\EPFL\\\\Deep Learning\\\\Miniprojects\\\\Proj_338157_338681_311699\\\\Miniproject2\\\\model.py'>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n-cPmIhvQ2FG"
   },
   "outputs": [],
   "source": [
    "import model\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qmg9kJmxRre6"
   },
   "outputs": [],
   "source": [
    "def test_linear():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    linear_torch = nn.Linear(100, 1000)\n",
    "    initial_weight = linear_torch.weight.clone()\n",
    "    initial_bias = linear_torch.bias.clone()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = linear_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    linear_model = model.Linear(100, 1000)\n",
    "    assert linear_model.weight.shape == initial_weight.shape\n",
    "    assert linear_model.bias.shape == initial_bias.shape\n",
    "    assert torch.allclose(linear_model.weight.mean(), initial_weight.mean(), atol=1e-3, rtol=1e-2)\n",
    "    assert torch.allclose(linear_model.weight.std(), initial_weight.std(), atol=1e-3, rtol=1e-2)\n",
    "\n",
    "    linear_model.weight = initial_weight\n",
    "    linear_model.bias = initial_bias\n",
    "    output_model = linear_model(x_test)\n",
    "    gradwrtinput = linear_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    assert torch.allclose(linear_torch.weight.grad, linear_model.weight.grad)\n",
    "    assert torch.allclose(linear_torch.bias.grad, linear_model.bias.grad)\n",
    "    \n",
    "    print('Linear layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1652271010973,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "nhbFLX_rU4iR",
    "outputId": "515cfc37-ed93-424c-f76e-4ad7dcc3ca94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer ok\n"
     ]
    }
   ],
   "source": [
    "test_linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "qS-7JZHohE4-"
   },
   "outputs": [],
   "source": [
    "def test_conv():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    conv_torch = nn.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "    initial_weight = conv_torch.weight.clone()\n",
    "    initial_bias = conv_torch.bias.clone()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 32, 50, 50)).normal_().requires_grad_()\n",
    "    output = conv_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    conv_model = model.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "    assert conv_model.weight.shape == initial_weight.shape\n",
    "    assert conv_model.bias.shape == initial_bias.shape\n",
    "    assert torch.allclose(conv_model.weight.mean(), initial_weight.mean(), atol=1e-2, rtol=1e-2)\n",
    "    assert torch.allclose(conv_model.weight.var(), initial_weight.var(), atol=1e-2, rtol=1e-2)\n",
    "\n",
    "    conv_model.weight = initial_weight\n",
    "    conv_model.bias = initial_bias\n",
    "    output_model = conv_model(x_test)\n",
    "    gradwrtinput = conv_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output, atol=1e-2)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2)\n",
    "    assert torch.allclose(conv_torch.weight.grad, conv_model.weight.grad, atol=1e-2)\n",
    "    assert torch.allclose(conv_torch.bias.grad, conv_model.bias.grad, atol=1e-2)\n",
    "    \n",
    "    print('Convolutional layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "conv_torch = nn.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "initial_weight = conv_torch.weight.clone()\n",
    "initial_bias = conv_torch.bias.clone()\n",
    "# Batch size x input dimension\n",
    "x_test = torch.zeros((5, 32, 50, 50)).normal_().requires_grad_()\n",
    "output = conv_torch(x_test)\n",
    "gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "output.backward(gradwrtoutput)\n",
    "\n",
    "# Testing dimensions, initialization\n",
    "torch.set_grad_enabled(False)\n",
    "conv_model = model.Conv2d(32, 64, stride=2, padding=2, dilation=2, kernel_size=5)\n",
    "assert conv_model.weight.shape == initial_weight.shape\n",
    "assert conv_model.bias.shape == initial_bias.shape\n",
    "assert torch.allclose(conv_model.weight.mean(), initial_weight.mean(), atol=1e-2, rtol=1e-2)\n",
    "assert torch.allclose(conv_model.weight.var(), initial_weight.var(), atol=1e-2, rtol=1e-2)\n",
    "\n",
    "conv_model.weight = initial_weight\n",
    "conv_model.bias = initial_bias\n",
    "output_model = conv_model(x_test)\n",
    "gradwrtinput = conv_model.backward(gradwrtoutput)\n",
    "\n",
    "assert output_model.shape == output.shape\n",
    "assert torch.allclose(output_model, output, atol=1e-2)\n",
    "assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2)\n",
    "assert torch.allclose(conv_torch.weight.grad, conv_model.weight.grad, atol=1e-2)\n",
    "assert torch.allclose(conv_torch.bias.grad, conv_model.bias.grad, atol=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 23, 23])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 23, 23])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(*args):\n",
    "    print(args)\n",
    "    print(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([3, 5],)\n",
      "[3, 5]\n"
     ]
    }
   ],
   "source": [
    "test([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1652271567100,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "-Jj-tCSXjg2f",
    "outputId": "a37b2a3c-fca5-41bf-fec5-6c6b289cdc47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional layer ok\n"
     ]
    }
   ],
   "source": [
    "test_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_relu():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    relu_torch = nn.ReLU()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = relu_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    relu_model = model.ReLU()\n",
    "    output_model = relu_model(x_test)\n",
    "    gradwrtinput = relu_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    \n",
    "    print('ReLU layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU layer ok\n"
     ]
    }
   ],
   "source": [
    "test_relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sigmoid():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    sigmoid_torch = nn.Sigmoid()\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = sigmoid_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    sigmoid_model = model.Sigmoid()\n",
    "    output_model = sigmoid_model(x_test)\n",
    "    gradwrtinput = sigmoid_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad)\n",
    "    \n",
    "    print('Sigmoid layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid layer ok\n"
     ]
    }
   ],
   "source": [
    "test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mse():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    mse_torch = nn.MSELoss()\n",
    "    # Batch size x input dimension\n",
    "    target = torch.zeros((5, 100)).normal_()\n",
    "    x_test = torch.zeros((5, 100)).normal_().requires_grad_()\n",
    "    output = mse_torch(x_test, target)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    mse_model = model.MSE()\n",
    "    output_model = mse_model(x_test, target)\n",
    "    gradwrtinput = mse_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2, rtol=1e-2)\n",
    "    \n",
    "    print('MSE layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE layer ok\n"
     ]
    }
   ],
   "source": [
    "test_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nearest_upsampling():\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    upsample_torch = nn.Upsample(scale_factor=3)\n",
    "    # Batch size x input dimension\n",
    "    x_test = torch.zeros((5, 32, 8, 8)).normal_().requires_grad_()\n",
    "    output = upsample_torch(x_test)\n",
    "    gradwrtoutput = torch.zeros(output.shape).normal_()\n",
    "    output.backward(gradwrtoutput)\n",
    "\n",
    "    # Testing dimensions, initialization\n",
    "    torch.set_grad_enabled(False)\n",
    "    upsample_model = model.NNupsampling(scale_factor=3)\n",
    "    output_model = upsample_model(x_test)\n",
    "    gradwrtinput = upsample_model.backward(gradwrtoutput)\n",
    "\n",
    "    assert output_model.shape == output.shape\n",
    "    assert torch.allclose(output_model, output)\n",
    "    assert torch.allclose(gradwrtinput, x_test.grad, atol=1e-2, rtol=1e-2)\n",
    "    \n",
    "    print('Nearest upsample layer ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest upsample layer ok\n"
     ]
    }
   ],
   "source": [
    "test_nearest_upsampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "6fXNctqSDhZi"
   },
   "outputs": [],
   "source": [
    "def test_all():\n",
    "    test_linear()\n",
    "    test_conv()\n",
    "    test_relu()\n",
    "    test_sigmoid()\n",
    "    test_mse()\n",
    "    test_nearest_upsampling()\n",
    "    print('All tests ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1652271531295,
     "user": {
      "displayName": "Francesco Salvi",
      "userId": "17039456355099176000"
     },
     "user_tz": -120
    },
    "id": "LPF4A8pJDrd2",
    "outputId": "d2d1537d-fd82-4e2e-e056-d1d54d2dec31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer ok\n",
      "Convolutional layer ok\n",
      "ReLU layer ok\n",
      "Sigmoid layer ok\n",
      "MSE layer ok\n",
      "Nearest upsample layer ok\n",
      "All tests ok\n"
     ]
    }
   ],
   "source": [
    "test_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMBZ0Xu5ksaAiymbAn7TS2",
   "collapsed_sections": [],
   "name": "tests.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
